---
id: 138
topics: [13]
source: 4
---

# Background

Consider the problem of making change for $n$ cents using the fewest number of coins. Assume that each coin's value is an integer. The available denominations are quarters (25 cents), dimes (10 cents), nickels (5 cents), and pennies (1 cent).

# Parts

## a

Describe a greedy algorithm to make change using the fewest coins.

**Answer:** The greedy algorithm repeatedly selects the largest denomination that does not exceed the remaining amount: (1) Take as many quarters as possible: $q = \lfloor n/25 \rfloor$, remainder $r_1 = n - 25q$. (2) Take as many dimes as possible: $d = \lfloor r_1/10 \rfloor$, remainder $r_2 = r_1 - 10d$. (3) Take as many nickels as possible: $k = \lfloor r_2/5 \rfloor$, remainder $r_3 = r_2 - 5k$. (4) Use pennies for the rest: $p = r_3$.

## b

Prove that your greedy algorithm yields an optimal solution.

**Answer:** Any optimal solution uses at most 4 pennies (5 pennies = 1 nickel), at most 1 nickel (2 nickels = 1 dime), and at most 2 dimes (3 dimes = 1 quarter + 1 nickel). Suppose an optimal solution uses fewer than $q^* = \lfloor n/25 \rfloor$ quarters. Then at least 25 cents must be represented using dimes, nickels, and pennies, requiring at least 3 coins (e.g., 10+10+5), whereas a single quarter uses 1 coin. This contradicts optimality. The same argument applies recursively to dimes, nickels, and pennies.

## c

Analyze the time complexity of your algorithm.

**Answer:** The algorithm performs a constant number of arithmetic operations (divisions and subtractions) over a fixed set of denominations, so the time complexity is $O(1)$.
